{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The text interpreter : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m/         load_data.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imdb dataset\n"
     ]
    }
   ],
   "source": [
    "run load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m/                    load_data.py             text_classification.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/sara/Documents/pfe_sujets/Cours_TSP/medical_project_pfe/text_interpreter_f/fimdb_application'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to be able to interpret the prediction made by a randomforest classifier applied to a text instance. \n",
    "\n",
    "The three main steps are : \n",
    "\n",
    "        - Preprocessing : \n",
    "- The code text_preprocessing.py allows us to load the dataframe (it has to contain the following columns : patient_id, review_text, Class.) \n",
    "- Furthermore, the user could choose which cleaning operations he wants: (simple cleaning or add a step of stemming the text)  \n",
    "- The code return three objects : \n",
    "    \n",
    "    - X : a vector of shape (number of existing review_text). Each row is the processed review doc. \n",
    "    - y : a vector of the (int ) labels.\n",
    "    - df: the original dataframe.         \n",
    "   \n",
    "\n",
    "          - Learning : \n",
    " \n",
    "          - Interpreting \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sara/Documents/pfe_sujets/Cours_TSP/medical_project_pfe/text_interpreter_f\n"
     ]
    }
   ],
   "source": [
    "cd /Users/sara/Documents/pfe_sujets/Cours_TSP/medical_project_pfe/text_interpreter_f/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean the reviews from noisy words and punctuations\n",
      "stemming the reviews\n"
     ]
    }
   ],
   "source": [
    "import text_preprocessing\n",
    "text_train, y, df  = text_preprocessing.main([\"-filepath\",u'/Users/sara/Documents/pfe_sujets/Cours_TSP/medical_project_pfe/text_interpreter_f/fimdb_application/text_classification.csv',\n",
    "                                           \"-ntlk_clean\", \"True\",\n",
    "                                            \"-str_clean\",\"True\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Class                                        review_text\n",
       "0           0      0  plot : two teen couples go to a church party ,...\n",
       "1           1      0  the happy bastard's quick movie review \\ndamn ...\n",
       "2           2      0  it is movies like these that make a jaded movi...\n",
       "3           3      0   \" quest for camelot \" is warner bros . ' firs...\n",
       "4           4      0  synopsis : a mentally unstable man undergoing ..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from learning_rf import learning_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=25)\n",
    "rf , X, feature_names = learning_(rf, text_train, y, '/Users/sara/Documents/pfe_sujets/text_interpreter/random_forest_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from construct_tree_randomforest import build_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules used to predict sample   (0, 5850)\t0.0287839156482\n",
      "  (0, 11624)\t0.0588516681971\n",
      "  (0, 4828)\t0.0292977308807\n",
      "  (0, 6414)\t0.0540320154761\n",
      "  (0, 5988)\t0.0310415660971\n",
      "  (0, 10713)\t0.0534572277612\n",
      "  (0, 15278)\t0.0327048046393\n",
      "  (0, 13209)\t0.0491531204051\n",
      "  (0, 5971)\t0.0871974596494\n",
      "  (0, 1120)\t0.0407001539335\n",
      "  (0, 8124)\t0.104214509978\n",
      "  (0, 2346)\t0.0715687820692\n",
      "  (0, 14024)\t0.0353257760504\n",
      "  (0, 6020)\t0.0550089708646\n",
      "  (0, 1443)\t0.0431896999526\n",
      "  (0, 11198)\t0.0748428742918\n",
      "  (0, 10042)\t0.0433774646017\n",
      "  (0, 13359)\t0.138941328163\n",
      "  (0, 8193)\t0.036191382611\n",
      "  (0, 13292)\t0.0411743536053\n",
      "  (0, 14067)\t0.0617301815355\n",
      "  (0, 10172)\t0.0376813593174\n",
      "  (0, 7811)\t0.147828684205\n",
      "  (0, 14185)\t0.0738161092009\n",
      "  (0, 5179)\t0.047703733872\n",
      "  :\t:\n",
      "  (0, 6543)\t0.0900155973153\n",
      "  (0, 8059)\t0.0521597394121\n",
      "  (0, 11765)\t0.296272861073\n",
      "  (0, 310)\t0.0947138437515\n",
      "  (0, 1070)\t0.0811335351881\n",
      "  (0, 11174)\t0.0419509062342\n",
      "  (0, 8130)\t0.0734011061239\n",
      "  (0, 15497)\t0.0367971418816\n",
      "  (0, 6279)\t0.0987576203578\n",
      "  (0, 6246)\t0.130668374389\n",
      "  (0, 15198)\t0.0790438988945\n",
      "  (0, 11187)\t0.044113674873\n",
      "  (0, 13198)\t0.0416021180052\n",
      "  (0, 13184)\t0.12851863904\n",
      "  (0, 15417)\t0.133071574047\n",
      "  (0, 3733)\t0.0783341363907\n",
      "  (0, 2286)\t0.0987576203578\n",
      "  (0, 9610)\t0.0916230119799\n",
      "  (0, 12489)\t0.0538211235258\n",
      "  (0, 10312)\t0.106102977375\n",
      "  (0, 1735)\t0.0794082588365\n",
      "  (0, 1608)\t0.0653576667443\n",
      "  (0, 14444)\t0.0455306934211\n",
      "  (0, 9797)\t0.0740975428289\n",
      "  (0, 9157)\t0.0319009772875: \n"
     ]
    }
   ],
   "source": [
    "phrases, flag, classes, missing_words = build_infos(rf, X[1], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'throughout',\n",
       " u'project',\n",
       " u'bothered',\n",
       " u'using',\n",
       " u'except',\n",
       " u'gath',\n",
       " u'rent',\n",
       " u'non',\n",
       " u'macho',\n",
       " u'allur',\n",
       " u'numb',\n",
       " u'cameo',\n",
       " u'piec',\n",
       " u'wors',\n",
       " u'exposur',\n",
       " u'repetit',\n",
       " u'declined',\n",
       " u'plug',\n",
       " u'likely',\n",
       " u'zuck']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 0.0,\n",
       " 2: 1.0,\n",
       " 3: 0.0,\n",
       " 4: 0.0,\n",
       " 5: 0.0,\n",
       " 6: 0.0,\n",
       " 7: 0.0,\n",
       " 8: 0.0,\n",
       " 9: 0.0,\n",
       " 10: 0.0,\n",
       " 11: 0.0,\n",
       " 12: 0.0,\n",
       " 13: 0.0,\n",
       " 14: 0.0,\n",
       " 15: 0.0,\n",
       " 16: 0.0,\n",
       " 17: 1.0,\n",
       " 18: 1.0,\n",
       " 19: 0.0,\n",
       " 20: 0.0,\n",
       " 21: 0.0,\n",
       " 22: 0.0,\n",
       " 23: 0.0,\n",
       " 24: 1.0,\n",
       " 25: 0.0,\n",
       " 26: 0.0,\n",
       " 27: 0.0,\n",
       " 28: 0.0,\n",
       " 29: 0.0,\n",
       " 30: 0.0,\n",
       " 31: 0.0,\n",
       " 32: 1.0,\n",
       " 33: 1.0,\n",
       " 34: 0.0,\n",
       " 35: 0.0,\n",
       " 36: 1.0,\n",
       " 37: 1.0,\n",
       " 38: 0.0,\n",
       " 39: 0.0,\n",
       " 40: 0.0,\n",
       " 41: 0.0,\n",
       " 42: 1.0,\n",
       " 43: 0.0,\n",
       " 44: 0.0,\n",
       " 45: 0.0,\n",
       " 46: 1.0,\n",
       " 47: 0.0,\n",
       " 48: 0.0,\n",
       " 49: 0.0,\n",
       " 50: 1.0,\n",
       " 51: 0.0,\n",
       " 52: 0.0,\n",
       " 53: 1.0,\n",
       " 54: 0.0,\n",
       " 55: 1.0,\n",
       " 56: 0.0,\n",
       " 57: 1.0,\n",
       " 58: 0.0,\n",
       " 59: 0.0,\n",
       " 60: 0.0,\n",
       " 61: 0.0,\n",
       " 62: 0.0,\n",
       " 63: 0.0,\n",
       " 64: 1.0,\n",
       " 65: 0.0,\n",
       " 66: 0.0,\n",
       " 67: 0.0,\n",
       " 68: 0.0,\n",
       " 69: 0.0,\n",
       " 70: 0.0,\n",
       " 71: 1.0,\n",
       " 72: 0.0,\n",
       " 73: 1.0,\n",
       " 74: 0.0,\n",
       " 75: 0.0,\n",
       " 76: 1.0,\n",
       " 77: 1.0,\n",
       " 78: 0.0,\n",
       " 79: 0.0,\n",
       " 80: 0.0,\n",
       " 81: 0.0,\n",
       " 82: 0.0,\n",
       " 83: 0.0,\n",
       " 84: 1.0,\n",
       " 85: 1.0,\n",
       " 86: 0.0,\n",
       " 87: 1.0,\n",
       " 88: 0.0,\n",
       " 89: 0.0,\n",
       " 90: 0.0,\n",
       " 91: 0.0,\n",
       " 92: 0.0,\n",
       " 93: 0.0,\n",
       " 94: 0.0,\n",
       " 95: 0.0,\n",
       " 96: 0.0,\n",
       " 97: 1.0,\n",
       " 98: 0.0,\n",
       " 99: 0.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_words[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
